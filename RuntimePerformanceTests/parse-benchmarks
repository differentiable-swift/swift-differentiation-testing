#!/usr/bin/env python3

# This script is a quick-and-dirty parser for the `influx` outupt of package-benchmark: https://swiftpackageindex.com/ordo-one/package-benchmark/1.27.4/documentation/benchmark/exportingbenchmarks#Saved-Formats
# that converts it into the `customBiggerIsBetter` json format needed by `github-action-benchmark`: https://github.com/benchmark-action/github-action-benchmark?tab=readme-ov-file#examples.
# This format was chosen over the others for the following reasons.
# 1. Presents raw values instead of scaling them for pretty-prenting, normalization etc.
# 2. Contains platform information and timestamps, all benchmark results are incomplete without this information.
# package-benchmark does support `jmh` output, but **only** for benchmarks with a throughput metric, which ours are not using (as it's not a
# valuable metric in this case). Instead, this script just takes the 50th percentile result for each benchmark and passes that to the
# benchmark action.

import csv
import os
import json
import pandas as pd
from typing import Tuple  

gh_action_formatted = []
df_full = pd.read_csv("./benchmark-raw-output/Current_run.influx.csv", skiprows=1)
# select columns of interest
df = df_full[['measurement', 'test', 'metric', 'unit', 'percentile', 'value', 'iterations']]
# we care only about p50 at the moment
df_medians = df[df['percentile'] == 50.0]

gdf = df_medians.groupby(['measurement', 'test'])
for (test, result) in gdf:
    name_prefix = f"{test[0]} - {test[1]} - {result['metric'].iloc[0]}"
    for (_, row) in result.iterrows():
        metric = row['metric']
        value = row['value']
        name = f"{name_prefix} - {metric}"
        unit = row['unit']
        if metric == "runforward(ns)" or metric == "runreverse(ns)":
            unit = 'ns'  # hard-coded case because of custom metrics
        elif unit in ('K','M','G'):
            unit = ''  # value in influx format not affected by dimensionless units 
        gh_action_formatted.append({'name': name, 'unit': unit, 'value': value})

res = json.dumps(gh_action_formatted)
with open("bench-mean-results.json", "w") as f:
    f.write(res)
